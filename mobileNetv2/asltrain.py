# -*- coding: utf-8 -*-
"""asltrain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AqrGYd694BgDoUUhlnW9Uq25LcaES5ry

## Check hardware config
"""

#!nvidia-smi
#!rm -rf ./logs/

"""## Install dependencies

### Get data
"""

#!pip install tensorflow-gpu==1.14.0 gdown
import tensorflow as tf
print(tf.__version__)
#import gdown
import os
from tensorflow import keras
import tensorflow.keras.backend as K
from tensorflow.python.tools import freeze_graph
from keras.preprocessing.image import ImageDataGenerator
import datetime
from math import ceil

## Get data
asl_dataset_url = 'https://drive.google.com/uc?id=1i85b43AieqqVESBajCCrXTg9AIjIBLqL'
#output = 'asl-alphabet.zip'
#gdown.download(asl_dataset_url, output, quiet=False)
#!unzip -u -qq asl-alphabet.zip

#Globals
target_dims, num_classes = None, None
train_steps_per_epoch, val_steps_per_epoch = None, None
"""### Input data pipeline"""

#  Using the data Augmentation in traning data
train_steps_per_epoch, val_steps_per_epoch = 0,0
def data_pipeline():
  global num_classes, target_dims, train_steps_per_epoch, val_steps_per_epoch
  ptrain = "./asl_alphabet_train"
  pval = "./asl_alphabet_test"
  batch = 32
  size = 64
  target_dims = (64, 64, 3)
  num_classes = 29
  #datagen1 = ImageDataGenerator(rescale = 1. / 255)
  datagen1 = ImageDataGenerator(
      rescale=1. / 255,
      shear_range=0.2,
      zoom_range=0.2,
      rotation_range=30,
      width_shift_range=0.2,
      height_shift_range=0.2,
      horizontal_flip=False)

  datagen2 = ImageDataGenerator(rescale=1. / 255)

  train_generator = datagen1.flow_from_directory(
      ptrain,
      target_size=(size, size),
      batch_size=batch,
      class_mode='categorical')

  validation_generator = datagen2.flow_from_directory(
      pval,
      target_size=(size, size),
      batch_size=batch,
      class_mode='categorical')

  count1 = 0
  for root, dirs, files in os.walk(ptrain):
      for each in files:
          count1 += 1

  count2 = 0
  for root, dirs, files in os.walk(pval):
      for each in files:
          count2 += 1

  train_steps_per_epoch = ceil(count1 / batch)
  val_steps_per_epoch = ceil(count2 / batch)
  return train_generator, validation_generator

# model definition
def create_model():
  target_dims = (64, 64, 3)
  num_classes = 29
  model = keras.applications.mobilenet_v2.MobileNetV2(input_shape = target_dims, weights = None, include_top=True, classes= num_classes)
  print(type(model))
  print(model.inputs)
  print(model.outputs)
  #model.trainable = False
  #model.summary()
  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])
  return model

epochs = 50
opt = keras.optimizers.Adam()
earlystop = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=0, mode='auto')
cp_callback = keras.callbacks.ModelCheckpoint(filepath='asl_classifier.ckpt',
                                                 save_weights_only=True,
                                                 verbose=1)
model = create_model()
#log_dir="logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)
train_generator, validation_generator = data_pipeline()
model.fit_generator(train_generator,
                    validation_data=validation_generator,
                    epochs=epochs,
                    steps_per_epoch=train_steps_per_epoch,
                    validation_steps=val_steps_per_epoch,
                    callbacks = [earlystop],
                    verbose=1)

model.save_weights("weights.h5")

K.clear_session()
K.set_learning_phase(0)

model = create_model()
model.load_weights("weights.h5")

save_dir = "./tmp_{:%Y-%m-%d_%H%M%S}".format(datetime.datetime.now())
tf.saved_model.simple_save(K.get_session(),
                           save_dir,
                           inputs={"input": model.inputs[0]},
                           outputs={"output": model.outputs[0]})

freeze_graph.freeze_graph(None,
                          None,
                          None,
                          None,
                          model.outputs[0].op.name,
                          None,
                          None,
                          os.path.join(save_dir, "frozen_model.pb"),
                          False,
                          "",
                          input_saved_model_dir=save_dir)
